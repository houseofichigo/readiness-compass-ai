# AI Readiness Assessment v2.0
# Schema-date: 2025-08-03

meta:
  locale_default: en
  size_breakpoints:
    micro: 1-9
    small: 10-49
    medium: 50-249
    large: 250-999
    enterprise: 1000+
  max_visible_questions: 60
  tracks:
    TECH:   "Technical / Data-Lead"
    REG:    "Regulated / Compliance"
    GEN:    "General Business"
  track_detection:
    precedence:
      - if: "role in [CIO / CTO, IT Lead, Data / AI Lead, ML Engineer, Data Engineer, DevOps Engineer, Security Architect, Infrastructure Manager]"
        then: TECH
      - if: "computed.regulated or role in [Legal / Compliance Lead, Privacy Officer, Compliance Manager, Risk Manager, Audit Lead, Governance Officer]"
        then: REG
      - else: GEN
  weight_vectors:
    TECH: { strategy: 20, data: 30, tools: 20, automation: 15, people: 5, governance: 10 }
    REG:  { strategy: 10, data: 20, tools: 10, automation: 10, people: 5, governance: 45 }
    GEN:  { strategy: 25, data: 15, tools: 15, automation: 15, people: 15, governance: 15 }
  question_cap:
    max_questions: 60
    auto_hide: [D2, P6]
  computed_fields:
    regulated:
      logic: "M4_industry in ['Banking', 'Insurance', 'Healthcare', 'Government', 'Legal', 'Financial Services', 'Pharmaceuticals']"

section_0:
  purpose: "Collect organization profile for track detection and personalized recommendations."
  consent_banner:
    text: "By proceeding, you agree to process your data for this readiness report and related communications."
    type: banner
    required: true
 questions:
    - id: M0
      text: "Organization name"
      type: text
      required: true

    - id: M1
      text: "Full name"
      type: text
      required: true

    - id: M2
      text: "Business e-mail"
      type: email
      helper: "Use your work address (no Gmail, Hotmail, etc.)"
      required: true

    - id: M3
      text: "Primary role"
      type: single
      required: true
      choices:
        - value: "Founder / CEO"
          score: 4
          reasoning: "Senior leadership → high AI influence"
          model_input_context: "Respondent is C-level, with strong ability to steer AI strategy."
        - value: "C-level executive"
          score: 4
          reasoning: "Senior leadership → high AI influence"
          model_input_context: "Respondent is C-level, with strong ability to steer AI strategy."
        - value: "Head of Marketing"
          score: 2
          reasoning: "Functional leader, some AI exposure"
          model_input_context: "Respondent leads marketing—likely some AI use but not core to strategy."
        - value: "Head of Sales"
          score: 2
          reasoning: "Functional leader, some AI exposure"
          model_input_context: "Respondent leads sales—likely some AI use but not core to strategy."
        - value: "Head of Finance"
          score: 2
          reasoning: "Functional leader, some AI exposure"
          model_input_context: "Respondent leads finance—likely some analytical AI use, but not central."
        - value: "Head of Operations"
          score: 2
          reasoning: "Functional leader, some AI exposure"
          model_input_context: "Respondent leads operations—may use process-automation AI, but not core."
        - value: "Product Lead"
          score: 3
          reasoning: "Product management often drives AI feature roadmaps"
          model_input_context: "Respondent leads product—likely directly engaged in AI/ML features."
        - value: "HR Lead"
          score: 1
          reasoning: "Low direct AI influence"
          model_input_context: "Respondent leads HR—AI use is typically more limited."
        - value: "Customer Support Lead"
          score: 1
          reasoning: "Low direct AI influence"
          model_input_context: "Respondent leads support—may use basic AI but not strategic."
        - value: "CIO / CTO"
          score: 5
          reasoning: "Technical leadership → very high AI influence"
          model_input_context: "Respondent is CIO/CTO—primary sponsor for AI infrastructure."
        - value: "IT Lead"
          score: 4
          reasoning: "Senior technical role → high AI influence"
          model_input_context: "Respondent leads IT—strong role in selecting AI platforms."
        - value: "Data / AI Lead"
          score: 5
          reasoning: "Direct AI ownership"
          model_input_context: "Respondent is Data/AI Lead—very familiar with AI use-cases."
        - value: "ML Engineer"
          score: 5
          reasoning: "Hands-on AI practitioner"
          model_input_context: "Respondent is ML Engineer—deep technical AI expertise."
        - value: "Data Engineer"
          score: 4
          reasoning: "Key enabler of data pipelines for AI"
          model_input_context: "Respondent is Data Engineer—critical to AI data readiness."
        - value: "DevOps Engineer"
          score: 3
          reasoning: "Supports deployment, less direct strategy"
          model_input_context: "Respondent is DevOps—helps productionize AI but not strategic lead."
        - value: "Security Architect"
          score: 3
          reasoning: "Enforces governance, moderate AI role"
          model_input_context: "Respondent is Security Architect—supports safe AI deployment."
        - value: "Infrastructure Manager"
          score: 3
          reasoning: "Manages platforms, moderate AI role"
          model_input_context: "Respondent is Infrastructure Manager—ensures compute for AI."
        - value: "Legal / Compliance Lead"
          score: 2
          reasoning: "Governance focus, indirect AI influence"
          model_input_context: "Respondent is Legal/Compliance—ensures AI policies but not strategy."
        - value: "Privacy Officer"
          score: 2
          reasoning: "Governance focus, indirect AI influence"
          model_input_context: "Respondent is Privacy Officer—focus on data privacy over AI strategy."
        - value: "Compliance Manager"
          score: 2
          reasoning: "Governance focus, indirect AI influence"
          model_input_context: "Respondent is Compliance Manager—ensures AI compliance but not adoption lead."
        - value: "Risk Manager"
          score: 1
          reasoning: "Risk oversight, limited AI adoption role"
          model_input_context: "Respondent is Risk Manager—focuses on risk rather than AI enablement."
        - value: "Audit Lead"
          score: 1
          reasoning: "Audit focus, limited AI adoption role"
          model_input_context: "Respondent is Audit Lead—may audit AI but not drive adoption."
        - value: "Governance Officer"
          score: 1
          reasoning: "Governance focus, limited AI adoption role"
          model_input_context: "Respondent is Governance Officer—ensures policy, not AI delivery."

    - id: M4_industry
      text: "Industry & sub-sector"
      type: dropdown
      required: true
      choices:
        - value: "Agriculture, Forestry & Fishing"
          score: 2
          reasoning: "Early AI pilots in precision agriculture, but overall low adoption"
          model_input_context: "Respondent’s industry is Agriculture—emerging AI use in precision farming."
        - value: "Mining & Quarrying"
          score: 2
          reasoning: "AI used for safety and optimization, but limited breadth"
          model_input_context: "Respondent’s industry is Mining—AI adoption growing in safety/optimization."
        - value: "Utilities (Electricity, Gas, Water & Waste)"
          score: 4
          reasoning: "Strong use of AI for grid management, predictive maintenance"
          model_input_context: "Respondent’s industry is Utilities—advanced AI for operations and maintenance."
        - value: "Construction"
          score: 1
          reasoning: "Very low AI adoption, mostly manual workflows"
          model_input_context: "Respondent’s industry is Construction—very early AI stage."
        - value: "Manufacturing"
          score: 4
          reasoning: "Extensive use of AI/automation in factories and supply chains"
          model_input_context: "Respondent’s industry is Manufacturing—high AI maturity in automation."
        - value: "Wholesale Trade"
          score: 3
          reasoning: "Moderate AI adoption in inventory and logistics optimization"
          model_input_context: "Respondent’s industry is Wholesale—using AI for inventory forecasting."
        - value: "Retail Trade"
          score: 3
          reasoning: "AI used in personalization and demand forecasting, moderate maturity"
          model_input_context: "Respondent’s industry is Retail—AI in recommendation engines and forecasting."
        - value: "Transportation & Warehousing"
          score: 2
          reasoning: "Emerging AI in logistics and route optimization"
          model_input_context: "Respondent’s industry is Transportation—AI pilots in routing and warehousing."
        - value: "Information & Communication Technology"
          score: 5
          reasoning: "Leading AI ecosystem with rapid adoption of generative models"
          model_input_context: "Respondent’s industry is ICT—very mature AI ecosystem."
        - value: "Finance & Insurance"
          score: 5
          reasoning: "High AI adoption in risk modeling, fraud detection"
          model_input_context: "Respondent’s industry is Finance—strong AI maturity in analytics."
        - value: "Real Estate & Rental & Leasing"
          score: 2
          reasoning: "Limited AI adoption beyond property valuation"
          model_input_context: "Respondent’s industry is Real Estate—early AI use in valuations."
        - value: "Professional, Scientific & Technical Services"
          score: 4
          reasoning: "Consulting and technical services heavily leverage AI"
          model_input_context: "Respondent’s industry is Professional Services—high AI usage."
        - value: "Administrative & Support & Waste Management Services"
          score: 3
          reasoning: "Moderate AI for process automation and waste analytics"
          model_input_context: "Respondent’s industry is Admin & Support—using AI for workflow automation."
        - value: "Educational Services"
          score: 3
          reasoning: "Growing AI in e-learning and administration"
          model_input_context: "Respondent’s industry is Education—AI in personalized learning and operations."
        - value: "Health Care & Social Assistance"
          score: 3
          reasoning: "Significant regulation but active AI in diagnostics and operations"
          model_input_context: "Respondent’s industry is Health Care—moderate AI maturity under compliance."
        - value: "Arts, Entertainment & Recreation"
          score: 2
          reasoning: "Early AI in content creation, still niche"
          model_input_context: "Respondent’s industry is Arts & Entertainment—exploring AI in creative processes."
        - value: "Accommodation & Food Services"
          score: 2
          reasoning: "AI pilots in demand forecasting and chatbots, limited scale"
          model_input_context: "Respondent’s industry is Accommodation—using AI intermittently in operations."
        - value: "Public Administration"
          score: 3
          reasoning: "AI in citizen services and analytics, moderate adoption"
          model_input_context: "Respondent’s industry is Public Admin—AI used in services and policy analysis."
        - value: "Non-profit & NGO"
          score: 2
          reasoning: "Limited budgets constrain AI experimentation"
          model_input_context: "Respondent’s industry is Non-profit—early AI use for analytics and fundraising."

    - id: M5_country
      text: "Country"
      type: dropdown
      required: true
      choices:
        - "Afghanistan"
        - "Albania"
        - "Algeria"
        - "Andorra"
        - "Angola"
        - "Antigua and Barbuda"
        - "Argentina"
        - "Armenia"
        - "Australia"
        - "Austria"
        - "Azerbaijan"
        - "Bahamas"
        - "Bahrain"
        - "Bangladesh"
        - "Barbados"
        - "Belarus"
        - "Belgium"
        - "Belize"
        - "Benin"
        - "Bhutan"
        - "Bolivia"
        - "Bosnia and Herzegovina"
        - "Botswana"
        - "Brazil"
        - "Brunei Darussalam"
        - "Bulgaria"
        - "Burkina Faso"
        - "Burundi"
        - "Cabo Verde"
        - "Cambodia"
        - "Cameroon"
        - "Canada"
        - "Central African Republic"
        - "Chad"
        - "Chile"
        - "China"
        - "Colombia"
        - "Comoros"
        - "Congo (Brazzaville)"
        - "Costa Rica"
        - "Côte d’Ivoire"
        - "Croatia"
        - "Cuba"
        - "Cyprus"
        - "Czech Republic"
        - "Democratic Republic of the Congo"
        - "Denmark"
        - "Djibouti"
        - "Dominica"
        - "Dominican Republic"
        - "Ecuador"
        - "Egypt"
        - "El Salvador"
        - "Equatorial Guinea"
        - "Eritrea"
        - "Estonia"
        - "Eswatini"
        - "Ethiopia"
        - "Fiji"
        - "Finland"
        - "France"
        - "Gabon"
        - "Gambia"
        - "Georgia"
        - "Germany"
        - "Ghana"
        - "Greece"
        - "Grenada"
        - "Guatemala"
        - "Guinea"
        - "Guinea-Bissau"
        - "Guyana"
        - "Haiti"
        - "Honduras"
        - "Hungary"
        - "Iceland"
        - "India"
        - "Indonesia"
        - "Iran"
        - "Iraq"
        - "Ireland"
        - "Israel"
        - "Italy"
        - "Jamaica"
        - "Japan"
        - "Jordan"
        - "Kazakhstan"
        - "Kenya"
        - "Kiribati"
        - "Kuwait"
        - "Kyrgyzstan"
        - "Laos"
        - "Latvia"
        - "Lebanon"
        - "Lesotho"
        - "Liberia"
        - "Libya"
        - "Liechtenstein"
        - "Lithuania"
        - "Luxembourg"
        - "Madagascar"
        - "Malawi"
        - "Malaysia"
        - "Maldives"
        - "Mali"
        - "Malta"
        - "Marshall Islands"
        - "Mauritania"
        - "Mauritius"
        - "Mexico"
        - "Micronesia"
        - "Moldova"
        - "Monaco"
        - "Mongolia"
        - "Montenegro"
        - "Morocco"
        - "Mozambique"
        - "Myanmar"
        - "Namibia"
        - "Nauru"
        - "Nepal"
        - "Netherlands"
        - "New Zealand"
        - "Nicaragua"
        - "Niger"
        - "Nigeria"
        - "North Macedonia"
        - "Norway"
        - "Oman"
        - "Palestine"
        - "Pakistan"
        - "Palau"
        - "Panama"
        - "Papua New Guinea"
        - "Paraguay"
        - "Peru"
        - "Philippines"
        - "Poland"
        - "Portugal"
        - "Qatar"
        - "Romania"
        - "Russia"
        - "Rwanda"
        - "Saint Kitts and Nevis"
        - "Saint Lucia"
        - "Saint Vincent and the Grenadines"
        - "Samoa"
        - "San Marino"
        - "São Tomé and Príncipe"
        - "Saudi Arabia"
        - "Senegal"
        - "Serbia"
        - "Seychelles"
        - "Sierra Leone"
        - "Singapore"
        - "Slovakia"
        - "Slovenia"
        - "Solomon Islands"
        - "Somalia"
        - "South Africa"
        - "South Korea"
        - "South Sudan"
        - "Spain"
        - "Sri Lanka"
        - "Sudan"
        - "Suriname"
        - "Sweden"
        - "Switzerland"
        - "Syria"
        - "Tajikistan"
        - "Thailand"
        - "Timor-Leste"
        - "Togo"
        - "Tonga"
        - "Trinidad and Tobago"
        - "Tunisia"
        - "Turkey"
        - "Turkmenistan"
        - "Tuvalu"
        - "Uganda"
        - "Ukraine"
        - "United Arab Emirates"
        - "United Kingdom"
        - "United States"
        - "Uruguay"
        - "Uzbekistan"
        - "Vanuatu"
        - "Venezuela"
        - "Vietnam"
        - "Yemen"
        - "Zambia"
        - "Zimbabwe"
      score_map_by_bucket:
        5:
          - "Australia"
          - "Canada"
          - "Denmark"
          - "France"
          - "Germany"
          - "Japan"
          - "Netherlands"
          - "Singapore"
          - "South Korea"
          - "Sweden"
          - "United Kingdom"
          - "United States"
        4:
          - "Austria"
          - "Belgium"
          - "Finland"
          - "Norway"
          - "Switzerland"
        3:
          - "Ireland"
          - "Italy"
          - "New Zealand"
          - "Spain"
        2:
          - "Brazil"
          - "China"
          - "India"
          - "Mexico"
          - "Russia"
          - "South Africa"
          - "*"    # wildcard for any other not listed
        1:
          - "Egypt"
          - "Nigeria"
          - "Philippines"

    - id: M6_size
      text: "Company size (FTE)"
      type: single
      required: true
      choices:
        - value: "1–9"
          score: 1
          reasoning: "Small companies adopt AI less frequently"
          model_input_context: "Organization is very small—limited AI resources."
        - value: "10–49"
          score: 2
          reasoning: "SMBs are starting to pilot AI"
          model_input_context: "Organization is small—early AI stage."
        - value: "50–249"
          score: 3
          reasoning: "Mid-sized firms adopt more AI"
          model_input_context: "Organization is mid-sized—moderate AI maturity."
        - value: "250–999"
          score: 4
          reasoning: "Larger organizations have dedicated AI teams"
          model_input_context: "Organization is large—higher AI maturity."
        - value: "≥ 1 000"
          score: 5
          reasoning: "Enterprise scale → strong AI capability"
          model_input_context: "Organization is enterprise—very strong AI maturity."
        - value: "Prefer not to say"
          score: 0
          reasoning: "No scoring data available"
          model_input_context: "Organization size not disclosed."

    - id: M7_revenue
      text: "Annual revenue"
      type: single
      required: true
      choices:
        - value: "< €250 k"
          score: 1
          reasoning: "Very limited budget for AI"
          model_input_context: "Organization’s revenue is very low—minimal AI funding."
        - value: "€250 k–1 M"
          score: 2
          reasoning: "Small budget constraints"
          model_input_context: "Organization’s revenue is low—some AI capacity but limited."
        - value: "€1 M–€5 M"
          score: 3
          reasoning: "Moderate funding for pilots"
          model_input_context: "Organization’s revenue is moderate—supports AI pilots."
        - value: "€5 M–€20 M"
          score: 4
          reasoning: "Good budget for multiple projects"
          model_input_context: "Organization’s revenue is strong—can scale AI."
        - value: "€20 M–€100 M"
          score: 5
          reasoning: "High funding for enterprise-scale AI"
          model_input_context: "Organization’s revenue is very strong—enterprise AI maturity."
        - value: "> €100 M"
          score: 5
          reasoning: "Enterprise-level funding"
          model_input_context: "Organization’s revenue is very strong—enterprise AI maturity."
computed:
  - id: regulated
    logic: |
      regulated_industries = [
        "Finance & Insurance",
        "Health Care & Social Assistance",
        "Utilities (Electricity, Gas, Water & Waste)",
        "Transportation & Warehousing",
        "Manufacturing",
        "Information & Communication Technology",
        "Professional, Scientific & Technical Services",
        "Administrative & Support & Waste Management Services",
        "Accommodation & Food Services"
      ]
      return response["M4_industry"] in regulated_industries

  - id: track
    logic: |
      tech_roles = [
        "CIO / CTO",
        "IT Lead",
        "Data / AI Lead",
        "ML Engineer",
        "Data Engineer",
        "DevOps Engineer",
        "Security Architect",
        "Infrastructure Manager"
      ]
      reg_roles = [
        "Legal / Compliance Lead",
        "Privacy Officer",
        "Compliance Manager",
        "Risk Manager",
        "Audit Lead",
        "Governance Officer"
      ]

      if response["M3"] in tech_roles:
        return "TECH"
      elif computed["regulated"] or response["M3"] in reg_roles:
        return "REG"
      else:
        return "GEN"
section_1:
  category: strategy
  purpose: "Assess strategic alignment & planning maturity."
  pillar_scores:
    strategy:
      logic: |
        ids = ["S1", "S7", "S8"]
        vals = [response[q] for q in ids]
        return sum(vals) / len(ids)
    planning_execution:
      logic: |
        ids = ["S2", "S4", "S5"]
        vals = [response[q] for q in ids]
        return sum(vals) / len(ids)
    process:
      logic: |
        ids = ["S3", "S6"]
        vals = [response[q] for q in ids]
        return sum(vals) / len(ids)
    organisation:
      logic: |
        ids = ["S9", "S10"]
        vals = [response[q] for q in ids]
        return sum(vals) / len(ids)
    measurement:
      logic: |
        ids = ["S11", "S12"]
        vals = [response[q] for q in ids]
        return sum(vals) / len(ids)

  questions:
    - id: S1
      text: "How many AI use cases have you identified for implementation within the next 12 months?"
      type: single
      helper: "Defines your planning maturity and readiness."
      choices:
        - value: "None"
          score: 1
          reasoning: "No use-cases = ad-hoc maturity"
          model_input_context: "Pre-exploration stage. No documented AI opportunities."
        - value: "Ideas listed only"
          score: 2
          reasoning: "Brainstormed but not formalised"
          model_input_context: "Early ideation stage. Informal AI discussions only."
        - value: "1–2 documented use cases"
          score: 3
          reasoning: "A few pilots = exploratory"
          model_input_context: "Initial documentation stage. Formal use-case docs exist."
        - value: "3–5 prioritised with owners"
          score: 4
          reasoning: "Prioritised projects with owners = defined roadmap"
          model_input_context: "Structured planning stage. Clear accountability assigned."
        - value: "6 or more with owners and timelines"
          score: 5
          reasoning: "Portfolio with owners & timelines = integrated strategy"
          model_input_context: "Portfolio management stage. Formal project management in place."
      required: true

    - id: S2
      text: "How do you decide which AI opportunities to pursue first?"
      type: single
      helper: "Select the process you currently use."
      show_if:
        S1:
          not_in: ["None", "Ideas listed only"]
      choices:
        - value: "No formal process"
          score: 1
          reasoning: "No process = ad-hoc"
          model_input_context: "Ad-hoc selection. No systematic framework."
        - value: "Ad hoc based on perceived value"
          score: 2
          reasoning: "Informal value assessment"
          model_input_context: "Uses business judgment without structured criteria."
        - value: "Impact × Effort matrix"
          score: 3
          reasoning: "Simple impact–effort scoring"
          model_input_context: "Standard 2×2 prioritization matrix."
        - value: "Impact × Effort + capacity weighting"
          score: 4
          reasoning: "Adds resource awareness"
          model_input_context: "Considers team capacity in prioritization."
        - value: "ROI-driven financial model"
          score: 5
          reasoning: "Quantitative ROI = mature planning"
          model_input_context: "Requires quantitative business case analysis."
        - value: "Risk-adjusted prioritisation"
          score: 5
          reasoning: "Weighs risk + return = best practice"
          model_input_context: "Integrates risk assessment into prioritization."
      required: true

    - id: S3
      text: "How integrated are your AI performance metrics with corporate KPIs or OKRs?"
      type: single
      helper: "Defines your measurement maturity."
      show_if:
        S1:
          not_in: ["None", "Ideas listed only"]
      choices:
        - value: "No AI KPIs/OKRs defined"
          score: 1
          reasoning: "No KPIs = no alignment"
          model_input_context: "No success criteria defined or tracked."
        - value: "KPIs drafted but not tracked"
          score: 2
          reasoning: "Metrics exist but not monitored"
          model_input_context: "Metrics created but no monitoring systems."
        - value: "KPIs tracked but not linked"
          score: 3
          reasoning: "Monitored but isolated"
          model_input_context: "AI metrics tracked separately from business OKRs."
        - value: "Partially aligned with departmental OKRs"
          score: 4
          reasoning: "Some functional linkage"
          model_input_context: "Connected to some department goals."
        - value: "Fully embedded in executive OKRs"
          score: 5
          reasoning: "Executive-level integration"
          model_input_context: "Tied directly to top-level objectives."
      required: true

    - id: S4
      text: "How do you estimate ROI for AI projects?"
      type: single
      helper: "Choose the method that matches your current practice."
      show_if:
        S1:
          not_in: ["None", "Ideas listed only"]
      choices:
        - value: "Don’t estimate ROI"
          score: 1
          reasoning: "No ROI modelling"
          model_input_context: "No financial analysis performed."
        - value: "Rough experience-based estimates"
          score: 2
          reasoning: "Informal estimates"
          model_input_context: "Uses intuition and past experience."
        - value: "Simple cost–benefit analysis"
          score: 3
          reasoning: "Basic structured analysis"
          model_input_context: "Compares costs against expected benefits."
        - value: "Linked ROI to clear KPIs and goals"
          score: 4
          reasoning: "ROI tied to metrics"
          model_input_context: "Connects returns to measurable outcomes."
        - value: "Detailed financial or risk-adjusted models"
          score: 5
          reasoning: "Advanced modelling"
          model_input_context: "Sophisticated analysis with risk factors."
      required: true

    - id: S5
      text: "What is your typical time from idea to measurable AI impact?"
      type: single
      helper: "Defines speed of execution."
      show_if:
        S1:
          not_in: ["None", "Ideas listed only"]
      choices:
        - value: "Over 12 months"
          score: 1
          reasoning: "Slow execution"
          model_input_context: "Traditional long-term project timelines."
        - value: "6–12 months"
          score: 2
          reasoning: "Moderate timeframe"
          model_input_context: "Standard enterprise delivery cycle."
        - value: "3–6 months"
          score: 3
          reasoning: "Standard pilot timeframe"
          model_input_context: "Balanced agile approach."
        - value: "1–3 months"
          score: 4
          reasoning: "Rapid pilot delivery"
          model_input_context: "Fast execution with existing platforms."
        - value: "Under 30 days"
          score: 5
          reasoning: "Very agile"
          model_input_context: "Off-the-shelf solutions and rapid iteration."
      required: true

    - id: S6
      text: "How do you monitor competitor or industry AI developments?"
      type: single
      helper: "Assesses market awareness."
      choices:
        - value: "Not tracked"
          score: 1
          reasoning: "No trend monitoring"
          model_input_context: "Operates without industry intelligence."
        - value: "Occasional ad hoc research"
          score: 2
          reasoning: "Sporadic benchmarking"
          model_input_context: "Irregular research efforts."
        - value: "Annual review"
          score: 3
          reasoning: "Scheduled but infrequent"
          model_input_context: "Periodic benchmarking cycle."
        - value: "Quarterly reporting"
          score: 4
          reasoning: "Regular updates"
          model_input_context: "Consistent monitoring with reports."
        - value: "Continuous dashboard or feed"
          score: 5
          reasoning: "Real-time monitoring"
          model_input_context: "Automated continuous intelligence feed."
      required: true

    - id: S7
      text: "Rank your top four strategic objectives for AI initiatives"
      type: rank
      helper: "Reveals strategic priorities."
      choices:
        - "Productivity"
        - "Cost reduction"
        - "Revenue growth"
        - "Customer experience"
        - "Innovation"
        - "Regulatory compliance"
        - "Investor positioning"
      max_rank: 4
      weight: [40, 30, 20, 10]
      reasoning: "Innovation/compliance goals score highest; productivity/cost near-term."
      model_input_context: "Priority mapping reflects strategic focus areas."
      required: true

    - id: S8
      text: "How aligned is your leadership team on AI strategy?"
      type: single
      helper: "Assesses executive sponsorship."
      choices:
        - value: "No alignment"
          score: 1
          reasoning: "No exec support"
          model_input_context: "Leadership operates without AI alignment."
        - value: "Occasional discussions"
          score: 2
          reasoning: "Minimal engagement"
          model_input_context: "Informal executive interest only."
        - value: "Executive interest without action"
          score: 3
          reasoning: "Interest but no budget"
          model_input_context: "Understands importance but no resources."
        - value: "Budget approved"
          score: 4
          reasoning: "Financial commitment"
          model_input_context: "Resources allocated for AI."
        - value: "Active executive sponsorship"
          score: 5
          reasoning: "Executive champions"
          model_input_context: "Leadership removes barriers and advocates AI."
      required: true

    - id: S9
      text: "Which teams are involved in defining AI use cases?"
      type: multi
      helper: "Measures cross-functional engagement."
      choices:
        - "Executive leadership"
        - "Product & marketing"
        - "Operations"
        - "Data & IT"
        - "Legal & compliance"
        - "HR"
        - "Finance"
        - "Customer support"
      score_per: 10
      cap: 100
      reasoning: "More functions = broader integration."
      model_input_context: "Breadth of departmental involvement."
      required: true

    - id: S10
      text: "How prepared is your organization to manage change from AI adoption?"
      type: single
      helper: "Assesses change-management readiness."
      choices:
        - value: "Not prepared"
          score: 1
          reasoning: "No framework"
          model_input_context: "No change management processes."
        - value: "Ad hoc readiness"
          score: 2
          reasoning: "Unstructured"
          model_input_context: "Occasional readiness activities."
        - value: "Formal process for some projects"
          score: 3
          reasoning: "Partial coverage"
          model_input_context: "Selective project-level readiness."
        - value: "Organization-wide framework"
          score: 4
          reasoning: "Standardised"
          model_input_context: "Enterprise-level change framework."
        - value: "Continuous improvement culture"
          score: 5
          reasoning: "Proactive culture"
          model_input_context: "Learning-driven continuous change."
      required: true

    - id: S11
      text: "How clear are the goals and metrics for your AI use cases?"
      type: single
      helper: "Assesses goal clarity and measurement."
      show_if:
        S1:
          not_in: ["None", "Ideas listed only"]
      choices:
        - value: "No clear goals"
          score: 1
          reasoning: "No metrics"
          model_input_context: "No objectives defined."
        - value: "Goals defined with no metrics"
          score: 2
          reasoning: "Unmeasured goals"
          model_input_context: "Objectives set but not tracked."
        - value: "Some metrics tracked"
          score: 3
          reasoning: "Partial measurement"
          model_input_context: "Metrics for subset of goals."
        - value: "Most goals with metrics"
          score: 4
          reasoning: "Broad measurement"
          model_input_context: "Majority of goals tracked."
        - value: "All goals have metrics & thresholds"
          score: 5
          reasoning: "Full measurement"
          model_input_context: "Complete metrics and thresholds."
      required: true

    - id: S12
      text: "What best describes your approach to piloting and deploying AI projects?"
      type: single
      helper: "Assesses deployment methodology."
      hide_if:
        P2: "Conservative – pilot tests before scaling"
      choices:
        - value: "POC only with strict compliance checks"
          score: 1
          reasoning: "Very cautious"
          model_input_context: "Proof-of-concept only."
        - value: "Small pilots with controlled access"
          score: 2
          reasoning: "Limited pilots"
          model_input_context: "Restricted pilot deployments."
        - value: "Case-by-case security review"
          score: 3
          reasoning: "Individual reviews"
          model_input_context: "Security checks per deployment."
        - value: "Agile testing with integrated oversight"
          score: 4
          reasoning: "Governed agility"
          model_input_context: "Rapid iterations under oversight."
        - value: "Fast iterations with production readiness & risk mgmt"
          score: 5
          reasoning: "Production-grade agility"
          model_input_context: "Rapid, risk-managed production deployments."
      required: true

section_2:
  category: governance
  purpose: "Assess financial readiness, runway, stakeholder support & compliance."
  pillar_scores:
    financial_strategy:
      logic: |
        ids = ["F1", "F3"]
        vals = [response[q] for q in ids]
        return sum(vals) / len(ids)
    investor_support:
      logic: |
        return response["F4"]
    regulatory_compliance:
      logic: |
        ids = ["F5", "F8"]
        vals = [response[q] for q in ids]
        return sum(vals) / len(ids)
    partnerships_ecosystem:
      logic: |
        return response["F6"]
    ethics_risk_management:
      logic: |
        return response["F7"]

  questions:
    - id: F1
      text: "What is your current monthly budget for AI and data initiatives?"
      type: single
      helper: "Defines your financial commitment level."
      choices:
        - value: "< €100"
          score: 1
          reasoning: "Minimal experimentation"
          model_input_context: "Spends under €100 monthly."
        - value: "€100–500"
          score: 2
          reasoning: "Basic tool coverage"
          model_input_context: "Modest budget for limited experimentation."
        - value: "€500–2 000"
          score: 3
          reasoning: "Supports a few pilots"
          model_input_context: "Budget for multiple pilot projects."
        - value: "€2 000–15 000"
          score: 4
          reasoning: "Multiple concurrent projects"
          model_input_context: "Advanced tooling and pilots."
        - value: "Over €15 000"
          score: 5
          reasoning: "Scaling potential"
          model_input_context: "Strategic investment scale."
      required: true

    - id: F3
      text: "How long can you fund your AI and data efforts without new investment or revenue?"
      type: single
      helper: "Indicates your financial runway."
      choices:
        - value: "Less than 3 months"
          score: 1
          reasoning: "Financial fragility"
          model_input_context: "Immediate funding pressure."
        - value: "3–6 months"
          score: 2
          reasoning: "Risk of interruptions"
          model_input_context: "Short-term runway."
        - value: "6–12 months"
          score: 3
          reasoning: "Sufficient for pilots"
          model_input_context: "Supports complete pilot cycles."
        - value: "12–24 months"
          score: 4
          reasoning: "Supports scaling"
          model_input_context: "Extended runway for scaling."
        - value: "Over 24 months"
          score: 5
          reasoning: "Stable long-term funding"
          model_input_context: "Sustainable AI investment."
      required: true

    - id: F4
      text: "How supportive are your board or investors of your AI initiatives?"
      type: single
      helper: "Assesses executive & investor backing."
      choices:
        - value: "Not supportive"
          score: 1
          reasoning: "Undermines projects"
          model_input_context: "No stakeholder alignment."
        - value: "Discussion only, no commitments"
          score: 2
          reasoning: "Conversations without resources"
          model_input_context: "Interest without commitment."
        - value: "Open to AI initiatives"
          score: 3
          reasoning: "Willingness to explore"
          model_input_context: "Conditional support stage."
        - value: "Budget approved"
          score: 4
          reasoning: "Financial backing in place"
          model_input_context: "Board-approved budget."
        - value: "Active championing"
          score: 5
          reasoning: "Executives champion AI"
          model_input_context: "Strategic sponsorship by board."
      required: true

    - id: F5
      text: "Which additional regulatory or security frameworks apply to your organization?"
      type: multi
      helper: "GDPR and EU AI Act apply by default."
      choices:
        - value: "None apply"
          score: 1
          reasoning: "No awareness of regulations"
          model_input_context: "Regulatory blindness."
        - value: "1–2 frameworks"
          score: 2
          reasoning: "Basic compliance awareness"
          model_input_context: "Identifies primary regulations."
        - value: "3–4 frameworks"
          score: 3
          reasoning: "Broader coverage"
          model_input_context: "Acknowledges multiple regulations."
        - value: "5–6 frameworks"
          score: 4
          reasoning: "Strong oversight"
          model_input_context: "Tracks most relevant requirements."
        - value: "> 6 frameworks"
          score: 5
          reasoning: "Comprehensive compliance"
          model_input_context: "Advanced regulatory management."
      score_per: 10
      cap: 100
      required: true

    - id: F6
      text: "What level of strategic partnerships do you have for AI?"
      type: single
      helper: "Assesses ecosystem engagement."
      choices:
        - value: "None"
          score: 1
          reasoning: "Isolation limits expertise"
          model_input_context: "No external partnerships."
        - value: "Exploratory discussions"
          score: 2
          reasoning: "Early outreach"
          model_input_context: "Preliminary partnership talks."
        - value: "One active partnership"
          score: 3
          reasoning: "Single collaboration"
          model_input_context: "One active AI vendor relationship."
        - value: "Multiple partnerships"
          score: 4
          reasoning: "Networked approach"
          model_input_context: "Several vendor/institution collaborations."
        - value: "Ecosystem collaboration (R&D + vendors)"
          score: 5
          reasoning: "Deep strategic collaborations"
          model_input_context: "Integrated R&D and vendor ecosystem."
      required: true

    - id: F7
      text: "What percentage of your AI budget is allocated to ethics and bias mitigation?"
      type: single
      helper: "Assesses ethical investment."
      choices:
        - value: "None"
          score: 1
          reasoning: "No allocation = compliance risk"
          model_input_context: "No ethics budget."
        - value: "Planned next fiscal year"
          score: 2
          reasoning: "Future intent"
          model_input_context: "Budget planned but not yet allocated."
        - value: "Under 5 % of AI budget"
          score: 3
          reasoning: "Modest funding"
          model_input_context: "Basic ethics activities supported."
        - value: "5–15 % of AI budget"
          score: 4
          reasoning: "Dedicated funding"
          model_input_context: "Substantial ethics investment."
        - value: "Over 15 % of AI budget"
          score: 5
          reasoning: "Significant investment"
          model_input_context: "Strategic ethics commitment."
      required: true
section_3:
  category: data
  purpose: "Data foundation, security, ethics, compliance."
  pillar_scores:
    data_environment:
      logic: |
        vals = [ response["D1"], response["D2"] ]
        return sum(vals) / len(vals)
    governance_policy:
      logic: |
        vals = [ response["D3"], response["D10"] ]
        return sum(vals) / len(vals)
    quality_observability:
      logic: |
        vals = [ response["D4"], response["D7"] ]
        return sum(vals) / len(vals)
    security_controls:
      logic: |
        return response["D5"]
    stewardship_enrichment:
      logic: |
        vals = [ response["D6"], response["D8"], response["D9"] ]
        return sum(vals) / len(vals)

  questions:
    - id: D1
      text: "Where is your most critical data primarily stored?"
      type: multi
      helper: "Critical data drives operations, decisions, and compliance."
      choices:
        - "Files & spreadsheets (e.g. Excel, Google Sheets, local files)"
        - "Databases (e.g. SQL, NoSQL, data warehouses)"
        - "Cloud & SaaS platforms (e.g. Google Drive, Salesforce, HubSpot)"
        - "Internal tools / legacy systems (e.g. custom apps, intranet)"
        - "Analytics & BI platforms (e.g. Power BI, Looker, Tableau)"
      score_per: 1
      cap: 5
      reasoning: "More source types = broader integration"
      model_input_context: "Data integration breadth indicates ecosystem complexity."
      required: true

    - id: D2
      text: "How much data does your organization generate or collect each month?"
      type: single
      choices:
        - value: "Don’t know"
          score: 1
          reasoning: "No awareness = poor data management"
          model_input_context: "Lacks visibility into data volumes."
        - value: "< 1 GB"
          score: 1
          reasoning: "Tiny datasets constrain AI"
          model_input_context: "Minimal data environment."
        - value: "1–10 GB"
          score: 2
          reasoning: "Limited data may inhibit modeling"
          model_input_context: "Small data volumes."
        - value: "10–100 GB"
          score: 3
          reasoning: "Moderate volume supports basic models"
          model_input_context: "Standard data volumes."
        - value: "≥ 100 GB"
          score: 4
          reasoning: "Large datasets enable sophisticated AI"
          model_input_context: "Substantial data volumes."
      required: true

    - id: D3
      text: "How mature is your data management (structure, tools, and lineage)?"
      type: single
      show_if:
        track: [TECH, REG]
      hide_if:
        all_of:
          - { M6_size: "1–9" }
          - { D1: { subset_of: ["Files & spreadsheets (e.g. Excel, Google Sheets, local files)"] } }
      choices:
        - value: "No standards or visibility"
          score: 1
          reasoning: "No standards = inconsistent & risky data"
          model_input_context: "No documented data processes."
        - value: "Basic naming conventions & partial docs"
          score: 2
          reasoning: "Minimal structure; manual processes"
          model_input_context: "Simple conventions, manual tracking."
        - value: "Defined standards with manual processes"
          score: 3
          reasoning: "Standards exist but lack automation"
          model_input_context: "Standards without tool support."
        - value: "Schema tools & automated tracking"
          score: 4
          reasoning: "Automated lineage = strong governance"
          model_input_context: "Uses schema tools for lineage."
        - value: "Version-controlled models & full lineage"
          score: 5
          reasoning: "End-to-end versioning & governance"
          model_input_context: "Comprehensive automated lineage."
      required: true

    - id: D4
      text: "How confident are you in the accuracy and freshness of your critical data?"
      type: single
      show_if:
        track: [TECH, REG]
      hide_if:
        all_of:
          - { M6_size: "1–9" }
          - { D1: { subset_of: ["Files & spreadsheets (e.g. Excel, Google Sheets, local files)"] } }
      choices:
        - value: "Low – data often outdated or unreliable"
          score: 1
          reasoning: "Poor quality yields unreliable AI"
          model_input_context: "Frequent data issues."
        - value: "Medium – manual checks"
          score: 2
          reasoning: "Some QC but error-prone"
          model_input_context: "Manual quality checks."
        - value: "High – periodic tests"
          score: 3
          reasoning: "Regular tests improve trust"
          model_input_context: "Scheduled data quality tests."
        - value: "Very high – automated alerts"
          score: 4
          reasoning: "Proactive alerting"
          model_input_context: "Automated data issue alerts."
        - value: "Excellent – real-time monitoring"
          score: 5
          reasoning: "Continuous validation = best practice"
          model_input_context: "Real-time quality assurance."
      required: true

    - id: D5
      text: "Which security controls protect your data infrastructure?"
      type: multi
      helper: "Security controls keep data safe—encryption, access controls, monitoring."
      choices:
        - "Encryption at rest (e.g. data encrypted on AWS S3 or Azure Blob Storage)"
        - "TLS/HTTPS in transit (e.g. API calls over HTTPS)"
        - "Role-based access controls (e.g. Google Cloud IAM, Azure RBAC)"
        - "Audit logs & monitoring (e.g. AWS CloudTrail, GCP Stackdriver)"
        - "Data Loss Prevention (DLP) (e.g. Google Cloud DLP, Azure Purview)"
        - "Tokenization (e.g. Vault-based tokenization of sensitive fields)"
        - "Differential privacy (e.g. noise injection for analytics)"
        - "None"
        - "I don’t know"
        - "Other (please specify)"
      score_per: 15
      cap: 100
      reasoning: "More controls = stronger security"
      model_input_context: "Number of implemented controls indicates security maturity."
      required: true

    - id: D6
      text: "How is data stewardship and cleaning managed?"
      type: single
      choices:
        - value: "No owner"
          score: 1
          reasoning: "No steward = neglect"
          model_input_context: "No designated data steward."
        - value: "Occasional clean-ups"
          score: 2
          reasoning: "Sporadic maintenance"
          model_input_context: "Reactive cleanup activities."
        - value: "Assigned owner with periodic review"
          score: 3
          reasoning: "Basic stewardship"
          model_input_context: "Owner assigned, periodic reviews."
        - value: "Dedicated steward with monthly routines"
          score: 4
          reasoning: "Regular maintenance"
          model_input_context: "Monthly stewardship routines."
        - value: "Continuous stewardship & monitoring"
          score: 5
          reasoning: "Ongoing oversight"
          model_input_context: "Continuous data monitoring."
      required: true

    - id: D7
      text: "How prepared are you for GDPR or EU AI Act audits?"
      type: single
      helper: "Indicate readiness for compliance or security audits."
      choices:
        - value: "None – no audit readiness"
          score: 1
          reasoning: "No audit capability = low trust"
          model_input_context: "No audit trails or docs."
        - value: "Basic logs only"
          score: 2
          reasoning: "Minimal traceability"
          model_input_context: "Simple logging only."
        - value: "Audit trail for critical systems"
          score: 3
          reasoning: "Key-system traceability"
          model_input_context: "Critical systems logged."
        - value: "Explainability logs + scripts"
          score: 4
          reasoning: "Explainability built into logs"
          model_input_context: "Logs include model rationale."
        - value: "Automated compliance checks"
          score: 5
          reasoning: "Fully automated audits"
          model_input_context: "Automated audit pipelines."
      required: true

    - id: D8
      text: "How mature is your data valueing and annotation process?"
      type: single
      show_if:
        track: [TECH, REG]
      choices:
        - value: "None"
          score: 1
          reasoning: "No values = hampers supervised learning"
          model_input_context: "No valueing process."
        - value: "Ad-hoc manual valueing"
          score: 2
          reasoning: "Unstructured values"
          model_input_context: "Manual ad-hoc valueing."
        - value: "Defined guidelines"
          score: 3
          reasoning: "Standard guidelines"
          model_input_context: "Formal valueing guidelines."
        - value: "Standard taxonomy across datasets"
          score: 4
          reasoning: "Unified taxonomy"
          model_input_context: "Consistent taxonomy applied."
        - value: "Automated valueing & ontology management"
          score: 5
          reasoning: "Automated enrichment"
          model_input_context: "Tool-driven valueing automation."
      required: true

    - id: D9
      text: "Do you use synthetic or third-party data to augment your datasets?"
      type: single
      show_if:
        track: TECH
      choices:
        - value: "No"
          score: 1
          reasoning: "No synthetic data = limits modelling"
          model_input_context: "No synthetic data usage."
        - value: "Exploring choices"
          score: 2
          reasoning: "Considering but not using"
          model_input_context: "Evaluating synthetic data."
        - value: "Limited pilots"
          score: 3
          reasoning: "Initial experiments"
          model_input_context: "Small-scale pilots."
        - value: "Regular production use"
          score: 4
          reasoning: "Mature usage"
          model_input_context: "Production synthetic data workflows."
        - value: "Extensive synthetic pipelines"
          score: 5
          reasoning: "Best practice"
          model_input_context: "Automated synthetic data pipelines."
      required: true

    - id: D10
      text: "How developed are your AI ethics and data privacy policies?"
      type: single
      helper: "Select the maturity stage of your policies and enforcement."
      choices:
        - value: "No formal policies"
          score: 1
          reasoning: "No policies = compliance risk"
          model_input_context: "No documented policies."
        - value: "High-level principles only"
          score: 2
          reasoning: "Principles exist but lack detail"
          model_input_context: "Principles without guidance."
        - value: "Documented guidelines (no training/oversight)"
          score: 3
          reasoning: "Guidelines exist but not enforced"
          model_input_context: "Docs without training."
        - value: "Guidelines + training & oversight"
          score: 4
          reasoning: "Training + oversight fosters adoption"
          model_input_context: "Workshops and reviews in place."
        - value: "Audited & continuously improved"
          score: 5
          reasoning: "Regular audits & updates = best practice"
          model_input_context: "Automated compliance cycles."
      required: true

section_4:
  category: tools
  purpose: "Tool stack & integration maturity (to power workflow and AI agent recommendations)."
  pillar_scores:
    toolset_breadth:
      logic: |
        return min(len(response["T0_tools"]), 5)
    integration_maturity:
      logic: |
        return (response["T1"] + response["T3"]) / 2
    reliability_resilience:
      logic: |
        return (response["T2"] + response["T7"]) / 2
    infrastructure_architecture:
      logic: |
        vals = [ response["T5"], response["T6"], response["T9"] ]
        return sum(vals) / len(vals)
    automation_execution:
      logic: |
        return (response["T4"] + response["T8"]) / 2

  questions:
    - id: T0_tools
      text: "Which tools are actively used by you and your team?"
      type: multi_group
      helper: "Select all tools your team uses—this drives tailored workflow and AI agent suggestions."
      score_by_count:
        "1": 0
        "2-3": 25
        "4-6": 50
        "7-9": 75
        ">=10": 100
      groups:
        - value: "Performance Monitoring"
          show_if: { track: TECH }
          choices:
            - "New Relic"
            - "Datadog"
            - "Dynatrace"
            - "AppDynamics"
            - "Elastic APM"
            - "Sentry"
            - "Splunk APM"
            - "Pingdom"
            - "Bubble"
            - "Mistral"
            - "Other performance monitoring tool (please specify)"
        - value: "Infrastructure & Network Monitoring"
          show_if: { track: TECH }
          choices:
            - "Zabbix"
            - "Nagios"
            - "PRTG"
            - "SolarWinds"
            - "Site24x7"
            - "ManageEngine"
            - "Grafana"
            - "Prometheus"
            - "Checkmk"
            - "Other infrastructure monitoring tool (please specify)"
        - value: "Cloud & DevOps Monitoring"
          show_if: { track: TECH }
          choices:
            - "AWS CloudWatch"
            - "Azure Monitor"
            - "Google Cloud Operations"
            - "LogicMonitor"
            - "Sumo Logic"
            - "PagerDuty"
            - "StatusPage"
            - "Other cloud monitoring tool (please specify)"
        - value: "Web Analytics & User Experience"
          show_if: { track: TECH }
          choices:
            - "Google Analytics"
            - "Adobe Analytics"
            - "Hotjar"
            - "Mixpanel"
            - "Amplitude"
            - "Tealium"
            - "Webflow"
            - "Matomo"
            - "Plausible"
            - "Other web analytics tool (please specify)"
        - value: "Data Management & ETL"
          show_if: { track: TECH }
          choices:
            - "Snowflake"
            - "Databricks"
            - "Fivetran"
            - "Stitch"
            - "Talend"
            - "Apache Airflow"
            - "Other data management tool (please specify)"
        - value: "API Integration & Workflow Automation"
          show_if: { track: TECH }
          choices:
            - "Zapier"
            - "Power Automate"
            - "MuleSoft"
            - "Make"
            - "n8n"
            - "Workato"
            - "Tray.io"
            - "Other automation tool (please specify)"
        - value: "Email Marketing & Communication"
          show_if: { track: GEN }
          choices:
            - "Mailchimp"
            - "Constant Contact"
            - "SendGrid"
            - "Campaign Monitor"
            - "ConvertKit"
            - "ActiveCampaign"
            - "GetResponse"
            - "Cordial"
            - "Brevo (Sendinblue)"
            - "AWeber"
            - "Other email marketing tool (please specify)"
        - value: "Customer Relations & Sales Management"
          show_if: { track: GEN }
          choices:
            - "Salesforce"
            - "HubSpot"
            - "Pipedrive"
            - "Zoho CRM"
            - "Freshsales"
            - "Monday.com"
            - "Close.io"
            - "Zendesk"
            - "Intercom"
            - "Other CRM tool (please specify)"
        - value: "E-commerce & Payment Processing"
          show_if: { track: GEN }
          choices:
            - "Shopify"
            - "WooCommerce"
            - "Stripe"
            - "PayPal"
            - "BigCommerce"
            - "Magento"
            - "Square"
            - "Other e-commerce tool (please specify)"
        - value: "Digital Advertising & Marketing"
          show_if: { track: GEN }
          choices:
            - "Google Ads"
            - "Facebook Ads"
            - "LinkedIn Ads"
            - "Microsoft Advertising"
            - "Twitter Ads"
            - "Pinterest Ads"
            - "TikTok Ads"
            - "Other advertising tool (please specify)"
        - value: "Business Intelligence & Analytics"
          show_if: { track: GEN }
          choices:
            - "Tableau"
            - "Power BI"
            - "Looker"
            - "Qlik Sense"
            - "Sisense"
            - "Domo"
            - "SurveyMonkey"
            - "Other BI tool (please specify)"
        - value: "Project Management & Productivity"
          show_if: { track: GEN }
          choices:
            - "Asana"
            - "Trello"
            - "Jira"
            - "Slack"
            - "Microsoft Teams"
            - "Notion"
            - "ClickUp"
            - "Other productivity tool (please specify)"
        - value: "Financial Management & Accounting"
          show_if: { track: GEN }
          choices:
            - "QuickBooks"
            - "Xero"
            - "FreshBooks"
            - "Sage"
            - "Wave"
            - "Odoo"
            - "Henrri.net"
            - "Other financial tool (please specify)"
        - value: "Business Process Management"
          show_if: { track: GEN }
          choices:
            - "Kissflow"
            - "Nintex"
            - "Pipefy"
            - "ProcessMaker"
            - "Appian"
            - "Pegasystems"
            - "Other workflow tool (please specify)"
        - value: "Data Privacy & GDPR Compliance"
          show_if: { track: REG }
          choices:
            - "OneTrust"
            - "TrustArc"
            - "CookieYes"
            - "Usercentrics"
            - "Didomi"
            - "Cookiebot"
            - "DataGrail"
            - "Other privacy tool (please specify)"
        - value: "Security & Risk Management"
          show_if: { track: REG }
          choices:
            - "Qualys"
            - "Rapid7"
            - "Tenable"
            - "CrowdStrike"
            - "SentinelOne"
            - "Splunk"
            - "Other security tool (please specify)"
        - value: "Audit & Governance"
          show_if: { track: REG }
          choices:
            - "AuditBoard"
            - "MetricStream"
            - "ServiceNow GRC"
            - "RSA Archer"
            - "LogicGate"
            - "Resolver"
            - "Other GRC tool (please specify)"
        - value: "Industry-Specific Compliance"
          show_if: { track: REG }
          choices:
            - "Fenergo"
            - "RegEd"
            - "Thomson Reuters"
            - "Other regulatory tool (please specify)"
        - value: "Document & Records Management"
          show_if: { track: REG }
          choices:
            - "SharePoint"
            - "DocuSign"
            - "Box"
            - "Dropbox Business"
            - "M-Files"
            - "FileHold"
      required: true

    - id: T1
      text: "How well are your tools and systems connected?"
      type: single
      choices:
        - value: "Siloed – no connections"
          score: 1
          reasoning: "Disconnected tools = poor scaling"
          model_input_context: "No integration between systems."
        - value: "Manual – CSV imports/exports"
          score: 2
          reasoning: "Labor-intensive, error-prone"
          model_input_context: "CSV-based manual syncs."
        - value: "Batch – scheduled syncs"
          score: 3
          reasoning: "Regular but delayed"
          model_input_context: "Scheduled batch integrations."
        - value: "API – platform integrations"
          score: 4
          reasoning: "Modern architecture"
          model_input_context: "API-driven connections."
        - value: "Real-time – event-driven mesh"
          score: 5
          reasoning: "Event-driven mesh = highest maturity"
          model_input_context: "Real-time event-driven integrations."
      required: true

    - id: T2
      text: "How often do data connections fail or cause issues?"
      type: single
      choices:
        - value: "Weekly – frequent failures"
          score: 1
          reasoning: "Frequent failures = low trust"
          model_input_context: "Systems fail weekly."
        - value: "Monthly – occasional errors"
          score: 2
          reasoning: "Some reliability issues"
          model_input_context: "Systems error monthly."
        - value: "Quarterly – rare problems"
          score: 3
          reasoning: "Fairly stable"
          model_input_context: "Quarterly issues."
        - value: "Almost never – very stable"
          score: 4
          reasoning: "High reliability"
          model_input_context: "Rare issues."
        - value: "Never – fully reliable"
          score: 5
          reasoning: "No failures = best practice"
          model_input_context: "Zero failures."
      required: true

    - id: T3
      text: "Who owns and maintains your system integrations?"
      type: single
      choices:
        - value: "No clear owner"
          score: 1
          reasoning: "No ownership = accountability gaps"
          model_input_context: "No integration accountability."
        - value: "External agency/freelancer"
          score: 2
          reasoning: "Outsourced, limited internal capacity"
          model_input_context: "External manages integrations."
        - value: "Ops/Product team"
          score: 3
          reasoning: "Shared responsibility"
          model_input_context: "Ops/Product share duties."
        - value: "Internal tech team"
          score: 4
          reasoning: "Dedicated capability"
          model_input_context: "Tech team owns integrations."
        - value: "Dedicated integration team"
          score: 5
          reasoning: "Specialized → high maturity"
          model_input_context: "Integration specialists."
      required: true

    - id: T4
      text: "How well are you connected to external AI services and LLMs?"
      type: single
      helper: "Indicates which LLMs you’re allowed or have in-house."
      choices:
        - value: "Not allowed"
          score: 1
          reasoning: "Bans LLMs = stifles innovation"
          model_input_context: "LLM usage prohibited."
        - value: "Exploratory tests only"
          score: 2
          reasoning: "Sandbox tests"
          model_input_context: "LLMs tested in sandbox."
        - value: "Pilot deployments (small projects)"
          score: 3
          reasoning: "Small-scale pilots"
          model_input_context: "Limited production pilots."
        - value: "One API in production"
          score: 4
          reasoning: "Single integration"
          model_input_context: "One LLM API live."
        - value: "Multiple APIs in production + internal LLM access"
          score: 5
          reasoning: "Broad integration"
          model_input_context: "Multiple APIs and internal models."
      required: true

    - id: T5
      text: "What access do you have to GPU/TPU compute?"
      type: single
      show_if: { track: [TECH, REG] }
      choices:
        - value: "None"
          score: 1
          reasoning: "No compute = restricts AI"
          model_input_context: "No GPU/TPU resources."
        - value: "Colab only"
          score: 2
          reasoning: "Free/shared → early stage"
          model_input_context: "Google Colab access only."
        - value: "On-demand cloud GPUs/TPUs"
          score: 3
          reasoning: "Pay-as-you-go"
          model_input_context: "Cloud-based compute."
        - value: "Dedicated GPU/TPU budget"
          score: 4
          reasoning: "Budgeted hardware"
          model_input_context: "Allocated compute budget."
        - value: "Managed AI compute cluster"
          score: 5
          reasoning: "Best practice cluster"
          model_input_context: "Dedicated AI cluster."
      required: true

    - id: T6
      text: "How well is your technical or data architecture documented?"
      type: single
      show_if: { track: [TECH, REG] }
      choices:
        - value: "None"
          score: 1
          reasoning: "No diagrams = ad-hoc systems"
          model_input_context: "No architecture docs."
        - value: "High-level sketches"
          score: 2
          reasoning: "Rough mapping"
          model_input_context: "Basic sketches only."
        - value: "Critical systems mapped"
          score: 3
          reasoning: "Key components documented"
          model_input_context: "Critical systems documented."
        - value: "Full architecture diagrams"
          score: 4
          reasoning: "Comprehensive documentation"
          model_input_context: "Detailed diagrams maintained."
        - value: "Auto-generated & maintained docs"
          score: 5
          reasoning: "Automated up-to-date docs"
          model_input_context: "Docs auto-generated."
      required: true

    - id: T7
      text: "What level of disaster recovery planning exists for data & AI?"
      type: single
      show_if: { track: [TECH, REG] }
      choices:
        - value: "No plan"
          score: 1
          reasoning: "No plan = high risk"
          model_input_context: "No recovery planning."
        - value: "Backups only"
          score: 2
          reasoning: "Limited resilience"
          model_input_context: "Backups without failover."
        - value: "Manual failover"
          score: 3
          reasoning: "Manual recovery"
          model_input_context: "Human-driven failover."
        - value: "Automated failover"
          score: 4
          reasoning: "Quick recovery"
          model_input_context: "Automated failover scripts."
        - value: "AI-aware recovery playbook"
          score: 5
          reasoning: "AI scenarios covered"
          model_input_context: "Playbooks include AI failures."
      required: true

    - id: T8
      text: "Which low-code or no-code platforms do you use for automation?"
      type: multi
      helper: "Select all platforms; choose None if none."
      choices:
        - value: "None – no low-code/no-code tools"
        - value: "Zapier – connect apps with workflows"
        - value: "Make – multi-step automation builder"
        - value: "n8n – self-hosted workflow automation"
        - value: "Power Automate – Microsoft flow automation"
        - value: "UiPath – RPA for desktop & web"
        - value: "Workato – enterprise integration platform"
        - value: "Airbyte – ELT data pipelines"
        - value: "Fivetran – automated data connectors"
        - value: "dbt – analytics engineering"
      score_per: 1
      cap: 5
      reasoning: "More tools = higher maturity"
      model_input_context: "Indicates automation maturity."
      required: true
section_5:
  category: automation
  purpose: "Automation maturity & AI agent governance."
  pillar_scores:
    strategy_scope:
      logic: |
        return response["A1"]
    agent_deployment:
      logic: |
        return response["A3"]
    execution_scale:
      logic: |
        vals = [ response["A2"], sum(response["A4"]) if isinstance(response["A4"], list) else response["A4"], sum(response["A8"]) if isinstance(response["A8"], list) else response["A8"] ]
        return sum(vals) / len(vals)
    governance_monitoring:
      logic: |
        vals = [ response["A6"], response["A9"], response["A11"] ]
        return sum(vals) / len(vals)
    risk_resilience:
      logic: |
        return (response["A7"] + response["A10"]) / 2

  questions:
    - id: A1
      text: "Which three tasks would most benefit from automation in your organization?"
      type: rank
      helper: "Rank your top priorities for automation."
      choices:
        - value: "Reporting"
          score: 1
        - value: "Scheduling"
          score: 1
        - value: "Data entry"
          score: 1
        - value: "FAQ handling"
          score: 1
        - value: "Ticket triage"
          score: 1
        - value: "Contract generation"
          score: 1
        - value: "Inventory management"
          score: 1
        - value: "Compliance checks"
          score: 1
        - value: "Other (please specify)"
          score: 0
      max_rank: 3
      weight: [40, 30, 20]
      reasoning: "Breadth indicates strategic focus."
      model_input_context: "Identifies key automation priorities."
      required: true

    - id: A1_other
      text: "Please specify your custom task for automation"
      type: text
      show_if:
        A1:
          contains: "Other (please specify)"
      required: true

    - id: A2
      text: "How mature are your current automation efforts?"
      type: single
      choices:
        - value: "None – no automation"
          score: 1
        - value: "1 – ad-hoc scripts only"
          score: 2
        - value: "2 – basic tools with manual oversight"
          score: 3
        - value: "3 – integrated workflows across functions"
          score: 4
        - value: "4 – continuous automation with monitoring"
          score: 5
        - value: "5 – fully autonomous processes"
          score: 5
      required: true

    - id: A3
      text: "What is the current status of AI agents in your operations?"
      type: single
      choices:
        - value: "None implemented – no AI agents"
          score: 1
        - value: "Prototype built – early proof of concept"
          score: 2
        - value: "One agent in production – single live agent"
          score: 3
        - value: "Multiple agents live – several agents running"
          score: 4
        - value: "Organization-wide deployment – agents across teams"
          score: 5
      required: true

    - id: A4
      text: "Which tasks are you considering for AI-agent automation?"
      type: multi
      helper: "Select all that apply."
      choices:
        - value: "Reporting"
        - value: "Scheduling"
        - value: "Data entry"
        - value: "FAQ handling"
        - value: "Ticket triage"
        - value: "Contract generation"
        - value: "Inventory management"
        - value: "Compliance checks"
      score_per: 10
      cap: 100
      reasoning: "Variety indicates maturity."
      model_input_context: "Range of agent use cases."
      required: true

    - id: A6
      text: "How do you monitor and alert on your automated processes?"
      type: single
      helper: "Ensures reliability and rapid issue resolution."
      choices:
        - value: "No monitoring"
          score: 1
        - value: "Manual checks"
          score: 2
        - value: "KPI dashboards"
          score: 3
        - value: "Automated alerts"
          score: 4
        - value: "Full observability & logging"
          score: 5
      required: true

    - id: A7
      text: "What are the main blockers to automating tasks and deploying AI agents?"
      type: multi
      helper: "Select all that apply."
      choices:
        - value: "Data silos"
        - value: "Lack of technical resources"
        - value: "Insufficient buy-in"
        - value: "Compliance concerns"
        - value: "Unclear ROI"
        - value: "Budget constraints"
        - value: "Integration complexity"
      score_formula: "100 - 10 * count"
      reasoning: "Fewer barriers = higher readiness."
      model_input_context: "Identifies adoption risks."
      required: true

    - id: A8
      text: "Which interface do you prefer for interacting with AI agents?"
      type: multi
      helper: "Helps tailor agent UI recommendations."
      choices:
        - value: "Chatbot (Slack/Teams)"
        - value: "Embedded widget"
        - value: "Dashboard"
        - value: "Email assistant"
        - value: "API/CLI"
        - value: "Voice assistant"
        - value: "Need guidance"
      score_per: 10
      cap: 100
      reasoning: "Interface diversity = higher maturity."
      model_input_context: "Indicates preferred agent access."
      required: true

    - id: A9
      text: "What governance processes do you have for AI agents?"
      type: single
      helper: "Ensures safe, compliant agent operations."
      choices:
        - value: "None"
          score: 1
        - value: "Ad-hoc spot checks"
          score: 2
        - value: "Formal review process"
          score: 3
        - value: "Logging with oversight"
          score: 4
        - value: "Continuous auditing"
          score: 5
      hide_if:
        A3: "None implemented – no AI agents"
      required: true

    - id: A10
      text: "What recovery or rollback strategy exists for failed automations or AI agents?"
      type: single
      helper: "Defines resilience and business continuity."
      choices:
        - value: "No plan"
          score: 1
        - value: "Manual rollback steps"
          score: 2
        - value: "Pre-defined failover procedures"
          score: 3
        - value: "Automated rollback"
          score: 4
        - value: "Self-healing loops"
          score: 5
      hide_if:
        A3: "None implemented – no AI agents"
      required: true

    - id: A11
      text: "How do you track the accuracy and quality of AI agent outputs?"
      type: single
      helper: "Drives training on output validation and testing."
      choices:
        - value: "No tracking"
          score: 1
        - value: "Manual spot checks"
          score: 2
        - value: "Release testing"
          score: 3
        - value: "Ongoing tests + spot checks"
          score: 4
        - value: "Continuous accuracy monitoring"
          score: 5
      hide_if:
        A3: "None implemented – no AI agents"
      required: true

section_6:
  category: people
  purpose: "Team capability & learning culture (to drive targeted training recommendations)."
  pillar_scores:
    adoption_engagement:
      logic: |
        vals = [ response["C1"], len(response["C8"]) if isinstance(response["C8"], list) else response["C8"], response["C9"] ]
        return sum(vals) / len(vals)
    skills_sharing:
      logic: |
        matrix_vals = list(response["C2"].values())
        vals = [ sum(matrix_vals) / len(matrix_vals), response["C3"], sum(response["C3a"]) if isinstance(response["C3a"], list) else response["C3a"] ]
        return sum(vals) / len(vals)
    training_investment:
      logic: |
        vals = [ response["C4"], response["C5"], response["C6"] ]
        return sum(vals) / len(vals)
    collaboration_safety:
      logic: |
        vals = [ response["C10"], response["C11"] ]
        return sum(vals) / len(vals)
    external_support:
      logic: |
        return response["C7"]

  questions:
    - id: C1
      text: "How often do you and your team use AI tools in your daily work?"
      type: single
      choices:
        - value: "Never"
          score: 1
        - value: "Rarely"
          score: 2
        - value: "Monthly"
          score: 3
        - value: "Weekly"
          score: 4
        - value: "Daily"
          score: 5
      required: true

    - id: C2
      text: "How confident are you and your team at these prompt-writing skills?"
      type: matrix
      rows:
        - "Writing basic prompts"
        - "Using few-shot examples"
        - "Formatting structured prompts"
        - "Designing multi-step prompt chains"
      columns:
        - value: "No confidence"
          score: 1
        - value: "Some confidence"
          score: 2
        - value: "Confident"
          score: 3
        - value: "Very confident"
          score: 4
      required: true

    - id: C3
      text: "How do you and your team share AI learnings internally?"
      type: single
      choices:
        - value: "None"
          score: 1
        - value: "Informal tips & tricks"
          score: 2
        - value: "Dedicated chat channel"
          score: 3
        - value: "Regular workshops"
          score: 4
        - value: "Active Community of Practice"
          score: 5
      required: true

    - id: C3a
      text: "Which AI training topics should you and your team prioritize? (Rank top 3)"
      type: rank
      choices:
        - value: "Prompt engineering"
          score: 3
        - value: "AI tool mastery"
          score: 3
        - value: "Data literacy"
          score: 3
        - value: "Model fine-tuning"
          score: 3
        - value: "Retrieval-augmented generation"
          score: 3
        - value: "Agent orchestration"
          score: 3
        - value: "Ethics & governance"
          score: 3
      max_rank: 3
      weight: [50, 30, 20]
      required: true

    - id: C4
      text: "What annual budget do you and your team allocate per person for AI upskilling?"
      type: single
      choices:
        - value: "0 €"
          score: 1
        - value: "< €200"
          score: 2
        - value: "200–500 €"
          score: 3
        - value: "500–1 000 €"
          score: 4
        - value: "> 1 000 €"
          score: 5
      required: true

    - id: C5
      text: "How many hours per month can you and your team dedicate to AI training?"
      type: single
      choices:
        - value: "None"
          score: 1
        - value: "< 1 hr"
          score: 2
        - value: "1–3 hrs"
          score: 3
        - value: "3–5 hrs"
          score: 4
        - value: "> 5 hrs"
          score: 5
      required: true

    - id: C6
      text: "What format do you and your team prefer for AI training delivery?"
      type: single
      choices:
        - value: "Text guides"
          score: 1
        - value: "Short videos"
          score: 2
        - value: "Live workshops"
          score: 3
        - value: "Self-paced courses"
          score: 4
        - value: "Mixed formats"
          score: 5
      required: true

    - id: C7
      text: "How often do you and your team engage external AI experts?"
      type: single
      choices:
        - value: "None – no external support"
          score: 1
        - value: "Occasional advice"
          score: 2
        - value: "Regular advisory sessions"
          score: 3
        - value: "Access to expert network"
          score: 4
        - value: "Dedicated AI advisory board"
          score: 5
      required: true

    - id: C8
      text: "What stops you and your team from piloting more AI projects?"
      type: multi
      choices:
        - value: "Budget constraints"
        - value: "Lack of skills"
        - value: "Data silos"
        - value: "Compliance concerns"
        - value: "Unclear ROI"
        - value: "Tech complexity"
      score_formula: "100 - 33 * count"
      reasoning: "Fewer blockers = higher readiness."
      required: true

    - id: C9
      text: "How open are you and your team to piloting new AI projects?"
      type: single
      choices:
        - value: "Resistant"
          score: 1
        - value: "Cautious"
          score: 2
        - value: "Interested"
          score: 3
        - value: "Proactive"
          score: 4
        - value: "Active pilots"
          score: 5
      required: true

    - id: C10
      text: "How frequently do you and your team collaborate across functions on AI initiatives?"
      type: single
      choices:
        - value: "Never"
          score: 1
        - value: "Occasionally"
          score: 2
        - value: "Quarterly"
          score: 3
        - value: "In squads"
          score: 4
        - value: "Embedded practice"
          score: 5
      required: true

    - id: C11
      text: "How safe do you and your team feel to experiment and fail with AI?"
      type: single
      choices:
        - value: "No safety – fear of repercussions"
          score: 1
        - value: "Low safety – rarely comfortable"
          score: 2
        - value: "Moderate safety – sometimes comfortable"
          score: 3
        - value: "High safety – often comfortable"
          score: 4
        - value: "Full safety – always encouraged"
          score: 5
      required: true
section_7:
  category: governance
  purpose: "Governance, risk & ethics (to drive targeted policy, oversight, and training recommendations)."
  pillar_scores:
    risk_and_bias_management:
      logic: |
        return response["G1"]
    explainability_transparency:
      logic: |
        vals = [ response["G2"], response["G3"] ]
        return sum(vals) / len(vals)
    incident_response_and_audit:
      logic: |
        vals = [ response["G4"], response["G7"], response["G8"], response["G9"] ]
        return sum(vals) / len(vals)
    oversight_and_compliance:
      logic: |
        vals = [ response["G5"], response["G6"] ]
        return sum(vals) / len(vals)
    fairness_and_ethics_oversight:
      logic: |
        return response["G10"]

  questions:
    - id: G1
      text: "How mature are your processes for identifying and mitigating AI risks and biases?"
      type: single
      choices:
        - value: "None"
          score: 1
        - value: "Reactive fixes"
          score: 2
        - value: "Pre-release checks"
          score: 3
        - value: "Formal framework"
          score: 4
        - value: "AI-Act–compliant"
          score: 5
      required: true

    - id: G2
      text: "How well can you explain and audit AI model decisions?"
      type: single
      choices:
        - value: "None"
          score: 1
        - value: "High-risk only"
          score: 2
        - value: "Audit logs"
          score: 3
        - value: "All models"
          score: 4
        - value: "Audit-ready"
          score: 5
      required: true

    - id: G3
      text: "How transparent are you with users and stakeholders about AI use?"
      type: single
      choices:
        - value: "None"
          score: 1
        - value: "Policy only"
          score: 2
        - value: "Docs & FAQs"
          score: 3
        - value: "Explain button"
          score: 4
        - value: "Full disclosure"
          score: 5
      required: true

    - id: G4
      text: "What level of incident response planning exists for AI failures or harms?"
      type: single
      choices:
        - value: "None"
          score: 1
        - value: "General IT plan"
          score: 2
        - value: "Manual rollback"
          score: 3
        - value: "Automated rollback"
          score: 4
        - value: "Playbook"
          score: 5
      required: true

    - id: G5
      text: "What level of human oversight do you enforce on AI outputs?"
      type: single
      choices:
        - value: "None"
          score: 1
        - value: "Final review"
          score: 2
        - value: "Spot checks"
          score: 3
        - value: "Human-in-loop"
          score: 4
        - value: "Escalation"
          score: 5
      required: true

    - id: G6
      text: "How deeply is privacy built into your AI development process?"
      type: single
      choices:
        - value: "Basic compliance"
          score: 1
        - value: "Enhanced controls"
          score: 2
        - value: "PETs"
          score: 3
        - value: "By design"
          score: 4
        - value: "Automated"
          score: 5
      required: true

    - id: G7
      text: "What is the status of independent audits for your AI systems?"
      type: single
      show_if: { track: [REG, TECH] }
      choices:
        - value: "None"
          score: 1
        - value: "Planned"
          score: 2
        - value: "In progress"
          score: 3
        - value: "Completed"
          score: 4
        - value: "Ongoing"
          score: 5
      required: true

    - id: G8
      text: "How far along are you in mapping AI risks under the EU AI Act?"
      type: single
      choices:
        - value: "Not aware"
          score: 1
        - value: "Aware"
          score: 2
        - value: "Mapping started"
          score: 3
        - value: "Completed"
          score: 4
        - value: "Reported"
          score: 5
      required: true

    - id: G9
      text: "How regularly do you test your AI models for fairness?"
      type: single
      show_if: { track: [REG, TECH] }
      choices:
        - value: "Never"
          score: 1
        - value: "Ad-hoc"
          score: 2
        - value: "Pre-release"
          score: 3
        - value: "Quarterly"
          score: 4
        - value: "Continuous"
          score: 5
      required: true

    - id: G10
      text: "What governance body oversees your AI ethics and compliance?"
      type: single
      choices:
        - value: "None"
          score: 1
        - value: "Informal"
          score: 2
        - value: "Ad-hoc"
          score: 3
        - value: "Scheduled"
          score: 4
        - value: "External"
          score: 5
      required: true

section_8:
  category: strategy
  purpose: "Implementation horizon, KPIs & vision (to align training and strategic planning)."
  pillar_scores:
    adoption_timeline:
      logic: |
        return response["P1"]
    risk_appetite:
      logic: |
        return response["P2"]
    success_metrics:
      logic: |
        vals = response["P3"]
        return sum(vals) / len(vals) if vals else 0
    resource_strategy:
      logic: |
        return response["P4"]
    architecture_preferences:
      logic: |
        vals = response["P5"]
        return sum(vals) / len(vals) if vals else 0
    external_support:
      logic: |
        return response["P6"]
    change_impact:
      logic: |
        return response["P7"]

  questions:
    - id: P1
      text: "When do you plan to roll out your AI initiatives?"
      type: single
      choices:
        - value: "Within 3 months"
          score: 5
        - value: "3–6 months"
          score: 4
        - value: "6–12 months"
          score: 3
        - value: "Over 12 months"
          score: 2
      required: true

    - id: P2
      text: "What level of risk are you comfortable taking on AI projects?"
      type: single
      choices:
        - value: "Conservative"
          score: 2
        - value: "Cautious"
          score: 3
        - value: "Balanced"
          score: 4
        - value: "Bold"
          score: 5
      required: true

    - id: P3
      text: "Which success metrics are most important for your AI work? (Select up to 3)"
      type: multi
      max_select: 3
      choices:
        - value: "Return on Investment (ROI)"
          score: 5
        - value: "Cost reduction"
          score: 4
        - value: "Operational efficiency"
          score: 4
        - value: "Customer experience"
          score: 3
        - value: "Employee productivity"
          score: 3
        - value: "Innovation outcomes"
          score: 5
        - value: "Regulatory compliance"
          score: 4
        - value: "Sustainability impact"
          score: 4
      required: true

    - id: P4
      text: "What is your preferred resource strategy for AI projects?"
      type: single
      choices:
        - value: "Fully in-house build"
          score: 5
        - value: "Hybrid"
          score: 4
        - value: "Fully outsourced"
          score: 2
      required: true

    - id: P5
      text: "Which technology architectures do you prefer for AI solutions? (Select all)"
      type: multi
      choices:
        - value: "Cloud-native"
          score: 5
        - value: "Hybrid/on-premise"
          score: 4
        - value: "API-first"
          score: 4
        - value: "Low-code/no-code"
          score: 3
        - value: "Open-source frameworks"
          score: 4
        - value: "Enterprise software suites"
          score: 3
      required: true

    - id: P6
      text: "What level of external support do you expect for AI implementation?"
      type: single
      choices:
        - value: "None"
          score: 1
        - value: "Occasional consulting"
          score: 2
        - value: "Ongoing advisory"
          score: 3
        - value: "Managed services"
          score: 4
        - value: "Full outsourcing"
          score: 2
      required: true

    - id: P7
      text: "How significant of an organizational change are you prepared for to adopt AI?"
      type: single
      choices:
        - value: "Minimal changes"
          score: 1
        - value: "Minor tweaks"
          score: 2
        - value: "Moderate transformation"
          score: 3
        - value: "Major transformation"
          score: 4
        - value: "Continuous evolution"
          score: 5
      required: true
add_ons:
  - id: T9
    show_if: { track: "TECH" }
    text: "How do you deploy ML models and monitor them in production?"
    type: single
    helper: "Deployment and monitoring ensure reliability and fast issue detection."
    choices:
      - value: "No deployment – models not in production"
        score: 1
      - value: "Manual scripts – ad-hoc launches"
        score: 2
      - value: "CI/CD pipeline – automated builds & deploys"
        score: 3
      - value: "MLOps platform (e.g. Kubeflow, MLflow) with monitoring"
        score: 4
      - value: "Fully automated blue/green deployments + rollback"
        score: 5
    required: true

  - id: F8
    show_if: { track: "REG" }
    text: "Which mechanisms do you use for cross-border data transfers?"
    type: single
    helper: "GDPR requires lawful transfer—select your standard approach."
    choices:
      - value: "No cross-border transfers"
        score: 1
      - value: "Ad-hoc contracts"
        score: 2
      - value: "Standard Contractual Clauses (SCCs)"
        score: 3
      - value: "Binding Corporate Rules (BCRs)"
        score: 4
      - value: "Adequacy decision + continuous monitoring"
        score: 5
    required: true

ui:
  progress_counter: true
  save_resume: true
  ranking_accessible: true
  mobile_touch_tested: true
  auto_deselect_none: true

validation:
  - rule: "Other selected → text field required"
  - rule: "All visible questions required"
  - rule: "Cap visible questions at 60; auto-hide D2 then P6"

scoring:
  use_explicit_option_scores: true
  weight_by_track: weight_vectors
  neutral_for_hidden: 50
  confidence_penalty:
    apply_to: [D2, unknown_like]

reporting:
  show_hidden_explanation: true
  benchmarks: by_track
  store_only: true
  admin_endpoint: /api/admin/assessment

version:
  assessment_version: "2.0"
  schema_date: "2025-08-03"

